from __future__ import print_function
from lib2to3.pgen2.tokenize import tokenize
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from sklearn.metrics import *
from matplotlib import pyplot as plt
from torch.utils.data import DataLoader
from models import *
from utils import *
from sampling import *
from datasets import *
import os
import random
from tqdm import tqdm
import copy
from operator import itemgetter
import time
from random import shuffle
from aggregation import *
from IPython.display import clear_output
import gc
import logging
from sklearn.neighbors import kneighbors_graph
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
import pickle
# from datetime import datetime  # å·²ç§»é™¤æ—¶é—´æˆ³ï¼Œä¸å†éœ€è¦

# DBONet æ•°æ®å½’ä¸€åŒ–å‡½æ•° (æ¥è‡ªåŸæ–‡)
def normalization(data):
    """æ•°æ®å½’ä¸€åŒ–å‡½æ•°"""
    maxVal = torch.max(data)
    minVal = torch.min(data)
    data = (data - minVal) / (maxVal - minVal + 1e-10)  # é¿å…é™¤é›¶
    return data

def standardization(data):
    """æ•°æ®æ ‡å‡†åŒ–å‡½æ•°"""
    rowSum = torch.sqrt(torch.sum(data**2, 1))
    repMat = rowSum.repeat((data.shape[1], 1)) + 1e-10
    data = torch.div(data, repMat.t())
    return data

class Peer():
    # Class variable shared among all the instances
    _performed_attacks = 0
    @property
    def performed_attacks(self):
        return type(self)._performed_attacks

    @performed_attacks.setter
    def performed_attacks(self,val):
        type(self)._performed_attacks = val

    def __init__(self, peer_id, peer_pseudonym, local_data, labels, criterion, 
                device, local_epochs, local_bs, local_lr, 
                local_momentum, peer_type = 'honest'):

        self.peer_id = peer_id
        self.peer_pseudonym = peer_pseudonym
        self.local_data = local_data
        self.labels = labels
        self.criterion = criterion
        self.device = device
        self.local_epochs = local_epochs
        self.local_bs = local_bs
        self.local_lr = local_lr
        self.local_momentum = local_momentum
        self.peer_type = peer_type
#======================================= Start of training function ===========================================================#
    def participant_update(self, global_epoch, model, attack_type = 'no_attack', malicious_behavior_rate = 0, 
                            source_class = None, target_class = None, dataset_name = None, rule = 'fedavg',
                            attack_config = None) :
        epochs = self.local_epochs
        train_loader = DataLoader(self.local_data, self.local_bs, shuffle = True, drop_last=True)
        attacked = 0
        local_features = []  # æ–°å¢ï¼šæ”¶é›†å¤šè§†å›¾ç‰¹å¾
        #Get the poisoned training data of the peer in case of label-flipping or backdoor attacks
        if (attack_type == 'label_flipping') and (self.peer_type == 'attacker'):
            r = np.random.random()
            if r <= malicious_behavior_rate:
                if dataset_name != 'IMDB':
                    # ä½¿ç”¨å¤æ‚æ”»å‡»é…ç½®æˆ–ç®€å•æ”»å‡»
                    poisoned_data = label_filp(self.local_data, source_class, target_class, 
                                             attack_config, global_epoch, self.peer_pseudonym)
                    train_loader = DataLoader(poisoned_data, self.local_bs, shuffle = True, drop_last=True)
                self.performed_attacks+=1
                attacked = 1
                
                # æ ¹æ®æ”»å‡»ç±»å‹æ‰“å°è¯¦ç»†çš„æ”»å‡»ä¿¡æ¯ï¼ˆä»…åœ¨ç¬¬ä¸€è½®æ˜¾ç¤ºï¼Œç”¨äºdebugï¼‰
                if attack_config and global_epoch == 0:
                    attack_type_name = attack_config.get('type', 'unknown')
                    
                    print(f'ğŸ”´ æ ‡ç­¾ç¿»è½¬æ”»å‡» [{self.peer_pseudonym}] (ç¬¬{global_epoch}è½®):')
                    print(f'   æ”»å‡»ç±»å‹: {attack_type_name}')
                    print(f'   ç´¯è®¡æ”»å‡»æ¬¡æ•°: {self.performed_attacks + 1}')
                    
                    if attack_type_name == 'multi_target':
                        # å¤šç›®æ ‡æ”»å‡»çš„è¯¦ç»†ä¿¡æ¯
                        mappings = attack_config.get('mappings', {})
                        flip_probs = attack_config.get('flip_probabilities', {})
                        print(f'   æ”»å‡»æ¨¡å¼: å¤šæº-å¤šç›®æ ‡æ ‡ç­¾ç¿»è½¬')
                        mapping_str = ', '.join([f'{src}â†’{tgt}' for src, tgt in mappings.items()])
                        print(f'   æ˜ å°„å…³ç³»: [{mapping_str}]')
                        if flip_probs:
                            prob_str = ', '.join([f'{src}({prob*100:.0f}%)' for src, prob in flip_probs.items()])
                            print(f'   ç¿»è½¬æ¦‚ç‡: [{prob_str}]')
                            
                    elif attack_type_name == 'probabilistic':
                        # æ¦‚ç‡æ€§æ”»å‡»çš„è¯¦ç»†ä¿¡æ¯
                        source_classes = attack_config.get('source_classes', [])
                        target_classes = attack_config.get('target_classes', [])
                        flip_rate = attack_config.get('flip_rate', 0.6)
                        randomize = attack_config.get('randomize_targets', False)
                        print(f'   æ”»å‡»æ¨¡å¼: æ¦‚ç‡æ€§éšæœºæ ‡ç­¾ç¿»è½¬')
                        print(f'   æºç±»åˆ«: {source_classes}')
                        print(f'   ç›®æ ‡ç±»åˆ«: {target_classes}')
                        print(f'   ç¿»è½¬æ¦‚ç‡: {flip_rate*100:.1f}%')
                        print(f'   éšæœºåŒ–: {"æ˜¯" if randomize else "å¦"}')
                        
                    elif attack_type_name == 'time_varying':
                        # æ—¶å˜æ”»å‡»çš„è¯¦ç»†ä¿¡æ¯
                        phases = attack_config.get('phases', [])
                        current_phase = None
                        phase_idx = 0
                        for i, phase in enumerate(phases):
                            epoch_range = phase['epochs']
                            if epoch_range[0] <= global_epoch < epoch_range[1]:
                                current_phase = phase
                                phase_idx = i + 1
                                break
                        print(f'   æ”»å‡»æ¨¡å¼: æ—¶å˜æ ‡ç­¾ç¿»è½¬')
                        print(f'   å½“å‰é˜¶æ®µ: {phase_idx}/{len(phases)}')
                        if current_phase:
                            mapping_str = ', '.join([f'{src}â†’{tgt}' for src, tgt in current_phase["mapping"].items()])
                            print(f'   å½“å‰æ˜ å°„: [{mapping_str}]')
                            print(f'   å½“å‰ç¿»è½¬ç‡: {current_phase.get("flip_rate", 1.0)*100:.1f}%')
                        
                    elif attack_type_name == 'adaptive':
                        # è‡ªé€‚åº”æ”»å‡»çš„è¯¦ç»†ä¿¡æ¯
                        stealth_mapping = attack_config.get('stealth_mapping', {})
                        aggressive_mapping = attack_config.get('aggressive_mapping', {})
                        threshold = attack_config.get('detection_threshold', 0.7)
                        print(f'   æ”»å‡»æ¨¡å¼: è‡ªé€‚åº”æ ‡ç­¾ç¿»è½¬')
                        print(f'   æ£€æµ‹é˜ˆå€¼: {threshold}')
                        stealth_str = ', '.join([f'{src}â†’{tgt}' for src, tgt in stealth_mapping.items()])
                        aggressive_str = ', '.join([f'{src}â†’{tgt}' for src, tgt in aggressive_mapping.items()])
                        print(f'   éšè”½æ˜ å°„: [{stealth_str}]')
                        print(f'   æ¿€è¿›æ˜ å°„: [{aggressive_str}]')
                        
                    elif attack_type_name == 'mixed':
                        # æ··åˆæ”»å‡»çš„è¯¦ç»†ä¿¡æ¯
                        label_flip_prob = attack_config.get('label_flip_prob', 0.6)
                        noise_prob = attack_config.get('noise_only_prob', 0.2)
                        mappings = attack_config.get('mappings', {})
                        print(f'   æ”»å‡»æ¨¡å¼: æ··åˆç­–ç•¥æ”»å‡»')
                        print(f'   æ ‡ç­¾ç¿»è½¬: {label_flip_prob*100:.1f}% | çº¯å™ªå£°: {noise_prob*100:.1f}%')
                        mapping_str = ', '.join([f'{src}â†’{tgt}' for src, tgt in mappings.items()])
                        print(f'   æ˜ å°„å…³ç³»: [{mapping_str}]')
                        
                    else:
                        # ç®€å•æ”»å‡»æˆ–æœªçŸ¥æ”»å‡»ç±»å‹
                        print(f'   æ”»å‡»æ¨¡å¼: ç®€å•å›ºå®šæ˜ å°„')
                        print(f'   æ˜ å°„å…³ç³»: [{source_class}â†’{target_class}]')
                        
                elif global_epoch == 0:
                    # æ— æ”»å‡»é…ç½®çš„ä¼ ç»Ÿç®€å•æ”»å‡»ï¼ˆä»…åœ¨ç¬¬ä¸€è½®æ˜¾ç¤ºï¼Œç”¨äºdebugï¼‰
                    print(f'ğŸ”´ æ ‡ç­¾ç¿»è½¬æ”»å‡» [{self.peer_pseudonym}] (ç¬¬{global_epoch}è½®):')
                    print(f'   æ”»å‡»ç±»å‹: ç®€å•æ ‡ç­¾ç¿»è½¬')
                    print(f'   æ”»å‡»æ¨¡å¼: å›ºå®šæ˜ å°„')
                    print(f'   æ˜ å°„å…³ç³»: [{source_class}â†’{target_class}]')
                    print(f'   ç´¯è®¡æ”»å‡»æ¬¡æ•°: {self.performed_attacks + 1}')
                    
                # è®­ç»ƒå®Œæˆåæ˜¾ç¤ºå…·ä½“çš„ç¿»è½¬è®°å½•
                # è¿™é‡Œå…ˆåˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„loaderæ¥è§¦å‘ç¿»è½¬è®°å½•
                if hasattr(poisoned_data, 'current_round_flips') and global_epoch == 0:
                    # å¿«é€Ÿé‡‡æ ·ä¸€å°éƒ¨åˆ†æ•°æ®æ¥ç”Ÿæˆç¿»è½¬è®°å½•ç”¨äºæ˜¾ç¤º
                    sample_size = min(50, len(poisoned_data))
                    for i in range(sample_size):
                        _ = poisoned_data[i]  # è§¦å‘__getitem__è®°å½•ç¿»è½¬
                    
                    flips = poisoned_data.get_current_round_flips()
                    if flips:
                        # ç»Ÿè®¡ç¿»è½¬æƒ…å†µ
                        flip_summary = {}
                        for flip in flips:
                            key = f"{flip['original']}â†’{flip['flipped']}"
                            flip_summary[key] = flip_summary.get(key, 0) + 1
                        
                        print(f'   å®é™…ç¿»è½¬è®°å½•:')
                        for flip_pattern, count in flip_summary.items():
                            print(f'   â€¢ {flip_pattern}: {count}æ¬¡')
        lr=self.local_lr

        if dataset_name == 'IMDB':
            optimizer = optim.Adam(model.parameters(), lr=lr)
        else:
            optimizer = optim.SGD(model.parameters(), lr=lr,
                        momentum=self.local_momentum, weight_decay=5e-4)
        model.train()
        epoch_loss = []
        peer_grad = []
        t = 0
        for epoch in range(epochs):
            correct, total = 0, 0
            for batch_idx, (data, target) in enumerate(train_loader):
                if dataset_name == 'IMDB':
                    target = target.view(-1,1) * (1 - attacked)

                data, target = data.to(self.device), target.to(self.device)
                if target.ndim > 1:
                    target = target.argmax(dim=-1)

                # åªæœ‰åœ¨ruleåŒ…å«'mv'æ—¶æ‰æå–å¤šè§†å›¾ç‰¹å¾
                if 'mv' in rule and hasattr(model, 'forward') and 'return_features' in model.forward.__code__.co_varnames:
                    features, output = model(data, return_features=True)
                    # åªä¿å­˜æœ€åä¸€ä¸ªbatchçš„ç‰¹å¾ä½œä¸ºä»£è¡¨ï¼ˆé¿å…è¿‡å¤šçš„ç‰¹å¾ç´¯ç§¯ï¼‰
                    if batch_idx == len(train_loader) - 1:  # æœ€åä¸€ä¸ªbatch
                        local_features.append(features)
                else:
                    output = model(data)
                loss = self.criterion(output, target)
                loss.backward()    
                epoch_loss.append(loss.item())
                # ç»Ÿè®¡æœ¬åœ°acc
                pred = output.argmax(dim=1)
                correct += (pred == target).sum().item()
                total += target.size(0)
                # get gradients
                cur_time = time.time()
                for i, (name, params) in enumerate(model.named_parameters()):
                    if params.requires_grad:
                        if epoch == 0 and batch_idx == 0:
                            peer_grad.append(params.grad.clone())
                        else:
                            peer_grad[i]+= params.grad.clone()   
                t+= time.time() - cur_time    
                optimizer.step()
                model.zero_grad()
                optimizer.zero_grad()
            # æ¯ä¸ªepochç»“æŸåæ‰“å°æœ¬åœ°loss/acc
            avg_loss = np.mean(epoch_loss[-len(train_loader):])
            acc = correct / total if total > 0 else 0
            # print(f'[Peer {self.peer_id}] Local Epoch {epoch+1}: Loss={avg_loss:.4f}, Acc={acc*100:.2f}%')
    
        if (attack_type == 'gaussian' and self.peer_type == 'attacker'):
            update, flag =  gaussian_attack(model.state_dict(), self.peer_pseudonym,
            malicious_behavior_rate = malicious_behavior_rate, device = self.device)
            if flag == 1:
                self.performed_attacks+=1
                attacked = 1
            model.load_state_dict(update)

        # åœ¨è®­ç»ƒç»“æŸåæ˜¾ç¤ºå®é™…ç¿»è½¬è®°å½•ï¼ˆä»…åœ¨ç¬¬ä¸€è½®æ˜¾ç¤ºä¸”å­˜åœ¨æ ‡ç­¾ç¿»è½¬æ”»å‡»æ—¶ï¼‰
        if (attack_type == 'label_flipping' and self.peer_type == 'attacker' and 
            attacked == 1 and global_epoch == 0 and 'poisoned_data' in locals()):
            try:
                if hasattr(poisoned_data, 'get_current_round_flips'):
                    all_flips = poisoned_data.get_current_round_flips()
                    if all_flips:
                        # ç»Ÿè®¡ç¿»è½¬æƒ…å†µ
                        flip_summary = {}
                        for flip in all_flips:
                            key = f"{flip['original']}â†’{flip['flipped']}"
                            flip_summary[key] = flip_summary.get(key, 0) + 1
                        
                        print(f'âœ… [{self.peer_pseudonym}] è®­ç»ƒå®Œæˆåå®é™…ç¿»è½¬ç»Ÿè®¡:')
                        for flip_pattern, count in flip_summary.items():
                            print(f'   â€¢ {flip_pattern}: {count}æ¬¡')
                        print(f'   æ€»ç¿»è½¬æ•°: {len(all_flips)}')
            except Exception as e:
                # é™é»˜å¤„ç†é”™è¯¯ï¼Œä¸å½±å“ä¸»æµç¨‹
                pass

        model = model.cpu()
        return model.state_dict(), peer_grad , model, np.mean(epoch_loss), attacked, t, local_features
#======================================= End of training function =============================================================#
#========================================= End of Peer class ====================================================================


class FL:
    def __init__(self, dataset_name, model_name, dd_type, num_peers, frac_peers, 
    seed, test_batch_size, criterion, global_rounds, local_epochs, local_bs, local_lr,
    local_momentum, labels_dict, device, attackers_ratio = 0,
    class_per_peer=2, samples_per_class= 250, rate_unbalance = 1, alpha = 1,source_class = None):

        FL._history = np.zeros(num_peers)
        self.dataset_name = dataset_name
        self.model_name = model_name
        self.num_peers = num_peers
        self.peers_pseudonyms = ['Peer ' + str(i+1) for i in range(self.num_peers)]
        self.frac_peers = frac_peers
        self.seed = seed
        self.test_batch_size = test_batch_size
        self.criterion = criterion
        self.global_rounds = global_rounds
        self.local_epochs = local_epochs
        self.local_bs = local_bs
        self.local_lr = local_lr
        self.local_momentum = local_momentum
        self.labels_dict = labels_dict
        self.num_classes = len(self.labels_dict)
        self.device = device
        self.attackers_ratio = attackers_ratio
        self.class_per_peer = class_per_peer
        self.samples_per_class = samples_per_class
        self.rate_unbalance = rate_unbalance
        self.source_class = source_class
        self.dd_type = dd_type
        self.alpha = alpha
        self.embedding_dim = 100
        self.peers = []
        self.trainset, self.testset = None, None
        
        # Fix the random state of the environment
        random.seed(self.seed)
        np.random.seed(self.seed)
        torch.manual_seed(self.seed)
        torch.cuda.manual_seed_all(self.seed)
        os.environ['PYTHONHASHSEED'] = str(self.seed)
       
        #Loading of data
        self.trainset, self.testset, user_groups_train, tokenizer = distribute_dataset(self.dataset_name, self.num_peers, self.num_classes, 
        self.dd_type, self.class_per_peer, self.samples_per_class, self.alpha)

        # è‡ªåŠ¨æ£€æŸ¥æ¨¡å‹å’Œæ•°æ®å°ºå¯¸æ˜¯å¦åŒ¹é…
        tmp_loader = DataLoader(self.trainset, batch_size=4, shuffle=True)
        inputs, _ = next(iter(tmp_loader))

        self.test_loader = DataLoader(self.testset, batch_size = self.test_batch_size,
            shuffle = False, num_workers = 1)
    
        #Creating model
        self.global_model = setup_model(model_architecture = self.model_name, num_classes = self.num_classes, 
        tokenizer = tokenizer, embedding_dim = self.embedding_dim)
        self.global_model = self.global_model.to(self.device)
        
        # Dividing the training set among peers
        self.local_data = []
        self.have_source_class = []
        self.labels = []
        print('--> Distributing training data among peers')
        
        for p in user_groups_train:
            self.labels.append(user_groups_train[p]['labels'])
            indices = user_groups_train[p]['data']
            peer_data = CustomDataset(self.trainset, indices=indices)
            self.local_data.append(peer_data)
            if  self.source_class in user_groups_train[p]['labels']:
                 self.have_source_class.append(p)
        print('--> Training data have been distributed among peers')

        # Creating peers instances
        print('--> Creating peets instances')
        m_ = 0
        if self.attackers_ratio > 0:
            #pick m random participants from the workers list
            # k_src = len(self.have_source_class)
            # print('# of peers who have source class examples:', k_src)
            m_ = int(self.attackers_ratio * self.num_peers)
            self.num_attackers = copy.deepcopy(m_)

        peers = list(np.arange(self.num_peers))  
        random.shuffle(peers)
        for i in peers:
            if m_ > 0 and contains_class(self.local_data[i], self.source_class):
                self.peers.append(Peer(i, self.peers_pseudonyms[i], 
                self.local_data[i], self.labels[i],
                self.criterion, self.device, self.local_epochs, self.local_bs, self.local_lr, 
                self.local_momentum, peer_type = 'attacker'))
                m_-= 1
            else:
                self.peers.append(Peer(i, self.peers_pseudonyms[i], 
                self.local_data[i], self.labels[i],
                self.criterion, self.device, self.local_epochs, self.local_bs, self.local_lr, 
                self.local_momentum))  

        del self.local_data

    #======================================= Multi-view and DBO Aggregation Functions =========================================#



    
    def _parameter_similarity_aggregation(self, simulation_model, local_weights):
        """åŸºäºå‚æ•°ç›¸ä¼¼æ€§çš„èšåˆæ–¹æ³• - æ— å›é€€æœºåˆ¶"""
        param_similarities = []
        global_params = list(simulation_model.parameters())[0].detach().cpu().numpy().flatten()
        
        for i, local_weight in enumerate(local_weights):
            local_param = list(local_weight.values())[0].cpu().numpy().flatten()
            similarity = np.dot(global_params, local_param) / (np.linalg.norm(global_params) * np.linalg.norm(local_param) + 1e-8)
            param_similarities.append(abs(similarity))
        
        weights = np.array(param_similarities)
        weights = weights / (np.sum(weights) + 1e-8)
        
        print(f"[Parameter Similarity] Using weights: {weights}")
        return average_weights(local_weights, weights)



#======================================= Start of testning function ===========================================================#
    def test(self, model, device, test_loader, dataset_name=None):
        from sklearn.metrics import f1_score
        
        model.eval()
        test_loss = []
        correct = 0
        n = 0
        all_preds = []
        all_targets = []
        
        for batch_idx, (data, target) in enumerate(test_loader):
            data, target = data.to(self.device), target.to(self.device)
            output = model(data)

            if dataset_name == 'IMDB':
                # IMDBäºŒåˆ†ç±»/å›å½’
                target_loss = target.float().view(-1, 1)
                loss = self.criterion(output, target_loss)
                pred = (output > 0.5).long().view(-1)
                target_acc = target.view(-1).long()
            else:
                # å¤šåˆ†ç±»ï¼Œç»Ÿä¸€targetä¸ºç±»åˆ«ç´¢å¼•
                if target.ndim > 1:
                    target = target.squeeze()  # ä¿®å¤ï¼šä½¿ç”¨squeezeè€Œä¸æ˜¯argmax
                loss = self.criterion(output, target)
                pred = output.argmax(dim=1)
                target_acc = target

            test_loss.append(loss.item())
            correct += (pred == target_acc).sum().item()
            n += target_acc.size(0)
            
            # æ”¶é›†é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾ç”¨äºF1 scoreè®¡ç®—
            all_preds.extend(pred.cpu().numpy())
            all_targets.extend(target_acc.cpu().numpy())

        test_loss = np.mean(test_loss) if test_loss else float('inf')
        accuracy = 100.0 * (correct / n)
        
        # è®¡ç®—F1 score
        try:
            if dataset_name == 'IMDB':
                # äºŒåˆ†ç±»F1 score
                f1 = f1_score(all_targets, all_preds, average='binary') * 100
            else:
                # å¤šåˆ†ç±»F1 score (macro average)
                f1 = f1_score(all_targets, all_preds, average='macro') * 100
        except:
            f1 = 0.0
        
        print('\nAverage test loss: {:.4f}, Test accuracy: {}/{} ({:.2f}%), F1 Score: {:.2f}%\n'.format(
            test_loss, correct, n, accuracy, f1))
        
        return accuracy, test_loss, f1
    #======================================= End of testning function =============================================================#
#Test label prediction function    
    def test_label_predictions(self, model, device, test_loader, dataset_name = None):
        model.eval()
        actuals = []
        predictions = []
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(self.device), target.to(self.device)
                output = model(data)
                if dataset_name == 'IMDB':
                    prediction = output > 0.5
                    target_processed = target.float().view(-1)
                else:
                    prediction = output.argmax(dim=1)
                    # ç¡®ä¿targetæ˜¯æ­£ç¡®çš„ç±»åˆ«ç´¢å¼•æ ¼å¼
                    if target.ndim > 1:
                        target_processed = target.squeeze()  # å‹ç¼©ç»´åº¦è€Œä¸æ˜¯argmax
                    else:
                        target_processed = target
                
                # ç¡®ä¿è½¬æ¢ä¸ºåˆ—è¡¨æ—¶ä¿æŒæ­£ç¡®çš„æ•°æ®æ ¼å¼
                actuals.extend(target_processed.cpu().numpy().tolist())
                predictions.extend(prediction.cpu().numpy().tolist())
        return actuals, predictions
    
    #choose random set of peers
    def choose_peers(self):
        #pick m random peers from the available list of peers
        m = max(int(self.frac_peers * self.num_peers), 1)
        selected_peers = np.random.choice(range(self.num_peers), m, replace=False)

        # print('\nSelected Peers\n')
        # for i, p in enumerate(selected_peers):
        #     print(i+1, ': ', self.peers[p].peer_pseudonym, ' is ', self.peers[p].peer_type)
        return selected_peers

        
    def run_experiment(self, attack_type = 'no_attack', malicious_behavior_rate = 0,
        source_class = None, target_class = None, rule = 'fedavg', resume = False, log_file="experiment.log",
        attack_config = None):
        # æ—¶é—´æˆ³å·²ç§»é™¤ï¼Œä½¿ç”¨å›ºå®šå‘½åæ–¹å¼
        # timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        logging.basicConfig(filename=log_file,
                            filemode='a',
                            format='%(asctime)s %(message)s',
                            level=logging.INFO)
        simulation_model = copy.deepcopy(self.global_model)
        print('\n===>Simulation started...')
        lfd = LFD(self.num_classes, attack_ratio=self.attackers_ratio)
        fg = FoolsGold(self.num_peers)
        tolpegin = Tolpegin()
        lfighter_dbo = LFighterDBO()
        lfighter_mv = LFighterMV()
        lfighter_mv_dbo = LFighterMVDBO()
        lfighter_ae = LFighterAutoencoder(
            self.num_classes, 
            enable_visualization=True,
            save_path="./figures/",
            attack_ratio=self.attackers_ratio
        )
        # è®¾ç½®æ€»è½®æ•°ç”¨äºPDFå¯è§†åŒ–æ§åˆ¶
        if rule == 'lfighter_ae':
            lfighter_ae.set_total_rounds(self.global_rounds)
        # copy weights
        global_weights = simulation_model.state_dict()
        last10_updates = []
        test_losses = []
        global_accuracies = []
        global_f1_scores = []
        source_class_accuracies = []
        cpu_runtimes = []
        noise_scalar = 1.0
        asr = 0.0  # åˆå§‹åŒ–ASRå˜é‡
        # best_accuracy = 0.0
        mapping = {'honest': 'Good update', 'attacker': 'Bad update'}

        #start training
        start_round = 0
        if resume:
            print('Loading last saved checkpoint..')
            checkpoint = torch.load('./checkpoints/'+ self.dataset_name + '_' + self.model_name + '_' + self.dd_type + '_'+ rule + '_'+ str(self.attackers_ratio) + '_' + str(self.local_epochs) + '.t7')
            simulation_model.load_state_dict(checkpoint['state_dict'])
            start_round = checkpoint['epoch'] + 1
            last10_updates = checkpoint['last10_updates']
            test_losses = checkpoint['test_losses']
            global_accuracies = checkpoint['global_accuracies']
            global_f1_scores = checkpoint.get('global_f1_scores', [])
            source_class_accuracies = checkpoint['source_class_accuracies']
            
            print('>>checkpoint loaded!')
        print("\n====>Global model training started...\n")
        for epoch in tqdm(range(start_round, self.global_rounds)):
            gc.collect()
            torch.cuda.empty_cache()
            
            # åˆå§‹åŒ–è§†å›¾æƒé‡å­—ç¬¦ä¸²
            view_weights_str = None
            
            # if epoch % 20 == 0:
            #     clear_output()  
            print(f'\n | Global training round : {epoch+1}/{self.global_rounds} |\n')
            selected_peers = self.choose_peers()
            local_weights, local_grads, local_models, local_losses, performed_attacks = [], [], [], [], []  
            all_local_features = []  # æ–°å¢ï¼šæ”¶é›†æ‰€æœ‰peerçš„ç‰¹å¾
            peers_types = []
            i = 1        
            attacks = 0
            Peer._performed_attacks = 0
            for peer in selected_peers:
                peers_types.append(mapping[self.peers[peer].peer_type])
                peer_update, peer_grad, peer_local_model, peer_loss, attacked, t, peer_features = self.peers[peer].participant_update(epoch, 
                copy.deepcopy(simulation_model),
                attack_type = attack_type, malicious_behavior_rate = malicious_behavior_rate, 
                source_class = source_class, target_class = target_class, dataset_name = self.dataset_name, rule = rule,
                attack_config = attack_config)
                local_weights.append(peer_update)
                local_grads.append(peer_grad)
                local_losses.append(peer_loss) 
                local_models.append(peer_local_model)
                all_local_features.append(peer_features)  # æ”¶é›†æ¯ä¸ªpeerçš„ç‰¹å¾
                attacks+= attacked
                # print('{} ends training in global round:{} |\n'.format((self.peers_pseudonyms[peer]), (epoch + 1))) 
                i+= 1
            # loss_avg = sum(local_losses) / len(local_losses)
            # print('Average of peers\' local losses: {:.6f}'.format(loss_avg))
            #aggregated global weights
            scores = np.zeros(len(local_weights))
            # Expected malicious peers
            f = int(self.num_peers*self.attackers_ratio)
            if rule == 'median':
                    cur_time = time.time()
                    global_weights = simple_median(local_weights)
                    cpu_runtimes.append(time.time() - cur_time)

            elif rule == 'rmedian':
                cur_time = time.time()
                global_weights = Repeated_Median_Shard(local_weights)
                cpu_runtimes.append(time.time() - cur_time)

            elif rule == 'tmean':
                    cur_time = time.time()
                    trim_ratio = self.attackers_ratio*self.num_peers/len(selected_peers)
                    global_weights = trimmed_mean(local_weights, trim_ratio = trim_ratio)
                    cpu_runtimes.append(time.time() - cur_time)

            elif rule == 'mkrum':
                cur_time = time.time()
                goog_updates = Krum(local_models, f = f, multi=True)
                scores[goog_updates] = 1
                global_weights = average_weights(local_weights, scores)
                cpu_runtimes.append(time.time() - cur_time)

            elif rule == 'foolsgold':
                cur_time = time.time()
                scores = fg.score_gradients(local_grads, selected_peers)
                global_weights = average_weights(local_weights, scores)
                cpu_runtimes.append(time.time() - cur_time + t)

            elif rule == 'Tolpegin':
                cur_time = time.time()
                scores = tolpegin.score(copy.deepcopy(self.global_model), 
                                            copy.deepcopy(local_models), 
                                            peers_types = peers_types,
                                            selected_peers = selected_peers)
                global_weights = average_weights(local_weights, scores)
                t = time.time() - cur_time
                print('Aggregation took', np.round(t, 4))
                cpu_runtimes.append(t)
            
            elif rule == 'FLAME':
                cur_time = time.time()
                global_weights = FLAME(copy.deepcopy(self.global_model).cpu(), copy.deepcopy(local_models), noise_scalar)
                t = time.time() - cur_time
                print('Aggregation took', np.round(t, 4))
                cpu_runtimes.append(t)


            elif rule == 'lfighter':
                cur_time = time.time()
                global_weights = lfd.aggregate(copy.deepcopy(simulation_model), copy.deepcopy(local_models), peers_types)
                cpu_runtimes.append(time.time() - cur_time)


            elif rule == 'lfighter_mv':
                cur_time = time.time()
                result = lfighter_mv.aggregate(simulation_model, local_weights, all_local_features, local_models, peers_types, lfd)
                if isinstance(result, tuple):
                    global_weights, view_weights_info = result
                    # æ ¼å¼åŒ–è§†å›¾æƒé‡ä¿¡æ¯ç”¨äºæ—¥å¿—
                    view_weights_str = f"Output:{view_weights_info['output_grad']:.3f},Activation:{view_weights_info['first_activation']:.3f},Input:{view_weights_info['input_grad']:.3f}"
                else:
                    global_weights = result
                    view_weights_str = "N/A"
                cpu_runtimes.append(time.time() - cur_time)

            elif rule == 'lfighter_dbo':
                cur_time = time.time()
                global_weights = lfighter_dbo.aggregate(simulation_model, local_weights, all_local_features)
                cpu_runtimes.append(time.time() - cur_time)

            elif rule == 'lfighter_mv_dbo':
                cur_time = time.time()
                result = lfighter_mv_dbo.aggregate(simulation_model, local_weights, all_local_features)
                if isinstance(result, tuple):
                    global_weights, view_weights_info = result
                    # æ ¼å¼åŒ–è§†å›¾æƒé‡ä¿¡æ¯ç”¨äºæ—¥å¿—
                    view_weights_str = f"Output:{view_weights_info['output_grad']:.3f},Activation:{view_weights_info['first_activation']:.3f},Input:{view_weights_info['input_grad']:.3f}"
                else:
                    global_weights = result
                    view_weights_str = "N/A"
                cpu_runtimes.append(time.time() - cur_time)

            elif rule == 'lfighter_ae':
                cur_time = time.time()
                global_weights = lfighter_ae.aggregate(copy.deepcopy(simulation_model), copy.deepcopy(local_models), peers_types)
                cpu_runtimes.append(time.time() - cur_time)

            elif rule == 'fedavg':
                cur_time = time.time()
                global_weights = average_weights(local_weights, [1 for i in range(len(local_weights))])
                cpu_runtimes.append(time.time() - cur_time)
            
            else:
                global_weights = average_weights(local_weights, [1 for i in range(len(local_weights))])
                ##############################################################################################
            #Plot honest vs attackers
            # if attack_type == 'label_flipping' and epoch >= 10 and epoch < 20:
            #     plot_updates_components(local_models, peers_types, epoch=epoch+1)   
            #     plot_layer_components(local_models, peers_types, epoch=epoch+1, layer = 'linear_weight')  
            #     plot_source_target(local_models, peers_types, epoch=epoch+1, classes= [source_class, target_class])
            # update global weights
            g_model = copy.deepcopy(simulation_model)
            simulation_model.load_state_dict(global_weights)           
            # èšåˆåæ‰“å°å…¨å±€æ¨¡å‹å‚æ•°å‡å€¼/æ–¹å·®
            params = list(simulation_model.parameters())
            print(f'[After aggregation] Epoch {epoch+1} global param mean: {params[0].data.mean().item():.6f}, std: {params[0].data.std().item():.6f}')
            if epoch >= self.global_rounds-10:
                last10_updates.append(global_weights) 

            current_accuracy, test_loss, current_f1 = self.test(simulation_model, self.device, self.test_loader, dataset_name=self.dataset_name)
            
            # ç§»é™¤NaNæ£€æŸ¥å›é€€æœºåˆ¶ - è®©çœŸå®é”™è¯¯æ˜¾ç¤º
            
            # è®¡ç®—å½“å‰è½®æ¬¡çš„ASR (åœ¨æ—¥å¿—è®°å½•ä¹‹å‰)
            actuals, predictions = self.test_label_predictions(simulation_model, self.device, self.test_loader, dataset_name=self.dataset_name)
            classes = list(self.labels_dict.keys())
            from sklearn.metrics import confusion_matrix
            cm = confusion_matrix(actuals, predictions, labels=classes)
            
            current_asr = 0.0  # å½“å‰è½®æ¬¡çš„ASR
            current_source_acc = 0.0  # å½“å‰è½®æ¬¡çš„æºç±»åˆ«å‡†ç¡®ç‡
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç§»ä½æ”»å‡»ï¼ˆä½¿ç”¨MULTI_TARGET_ATTACKé…ç½®ï¼‰
            is_shift_attack = False
            attack_mappings = {}
            if attack_config and attack_config.get('type') == 'multi_target':
                is_shift_attack = True
                attack_mappings = attack_config.get('mappings', {})
                
            if is_shift_attack:
                # ç§»ä½æ”»å‡»çš„ASRè®¡ç®—ï¼šæ‰€æœ‰æ˜ å°„ç±»åˆ«çš„å¹³å‡ASR
                total_source_samples = 0
                total_successful_attacks = 0
                
                for src_class, tgt_class in attack_mappings.items():
                    if src_class < len(cm) and np.sum(cm[src_class]) > 0:
                        # æºç±»åˆ«æ ·æœ¬ä¸­è¢«é¢„æµ‹ä¸ºç›®æ ‡ç±»åˆ«çš„æ¯”ä¾‹
                        source_samples = np.sum(cm[src_class])
                        successful_attacks = cm[src_class][tgt_class]
                        total_source_samples += source_samples
                        total_successful_attacks += successful_attacks
                        
                        # å¦‚æœæ˜¯æºç±»åˆ«ï¼Œè®°å½•å…¶å‡†ç¡®ç‡ï¼ˆç”¨äºå…¼å®¹ç°æœ‰ä»£ç ï¼‰
                        if src_class == source_class:
                            current_source_acc = np.round(cm[src_class][src_class]/source_samples*100, 2)
                            source_class_accuracies.append(current_source_acc)
                
                # è®¡ç®—å…¨å±€ASR
                if total_source_samples > 0:
                    current_asr = np.round(total_successful_attacks/total_source_samples*100, 2)
                    print(f"[ç§»ä½æ”»å‡»ASR] æ€»æºæ ·æœ¬: {total_source_samples}, æˆåŠŸæ”»å‡»: {total_successful_attacks}, ASR: {current_asr:.2f}%")
                    
                    # æ˜¾ç¤ºæ¯ä¸ªç±»åˆ«çš„è¯¦ç»†ASR
                    print("\nå„ç±»åˆ«ASRè¯¦æƒ…:")
                    for src_class, tgt_class in attack_mappings.items():
                        if src_class < len(cm) and np.sum(cm[src_class]) > 0:
                            class_asr = np.round(cm[src_class][tgt_class]/np.sum(cm[src_class])*100, 2)
                            print(f"[è½®æ¬¡{epoch+1} ASR] æºç±»åˆ«{src_class}({self.labels_dict.get(src_class, 'æœªçŸ¥')})â†’ç›®æ ‡ç±»åˆ«{tgt_class}({self.labels_dict.get(tgt_class, 'æœªçŸ¥')}): {class_asr:.2f}%")
            else:
                # ä¼ ç»Ÿå•ä¸€æº-ç›®æ ‡æ”»å‡»çš„ASRè®¡ç®—
                for i, r in enumerate(cm):
                    if i == source_class:
                        current_source_acc = np.round(r[i]/np.sum(r)*100, 2) if np.sum(r) > 0 else 0.0
                        source_class_accuracies.append(current_source_acc)
                        # è®¡ç®—ASR
                        if np.sum(r) > 0:
                            current_asr = np.round(r[target_class]/np.sum(r)*100, 2)
                        break
            
            global_accuracies.append(np.round(current_accuracy, 2))
            global_f1_scores.append(np.round(current_f1, 2))
            test_losses.append(np.round(test_loss, 4))
            performed_attacks.append(attacks) 
            
            # æ¯è½®è®­ç»ƒç»“æŸåå†™æ—¥å¿— (ç°åœ¨åŒ…å«ASR)
            if (rule == 'lfighter_mv' or rule == 'lfighter_mv_dbo') and 'view_weights_str' in locals() and view_weights_str is not None:
                log_msg = (
                    f"Round {epoch+1}/{self.global_rounds} | "
                    f"Global Acc: {current_accuracy:.2f} | "
                    f"Test Loss: {test_loss:.4f} | "
                    f"Attacks: {attacks} | "
                    f"Source Class Acc: {current_source_acc:.2f} | "
                    f"ASR: {current_asr:.2f}% | "
                    f"ViewWeights: {view_weights_str}"
                )
            else:
                log_msg = (
                    f"Round {epoch+1}/{self.global_rounds} | "
                    f"Global Acc: {current_accuracy:.2f} | "
                    f"Test Loss: {test_loss:.4f} | "
                    f"Attacks: {attacks} | "
                    f"Source Class Acc: {current_source_acc:.2f} | "
                    f"ASR: {current_asr:.2f}%"
                )
            print(log_msg)
            logging.info(log_msg)
            
            state = {
                'epoch': epoch,
                'state_dict': simulation_model.state_dict(),
                'global_model':g_model,
                'local_models':copy.deepcopy(local_models),
                'last10_updates':last10_updates,
                'test_losses': test_losses,
                'global_accuracies': global_accuracies,
                'global_f1_scores': global_f1_scores,
                'source_class_accuracies': source_class_accuracies
                }
            savepath = './checkpoints/'+ self.dataset_name + '_' + self.model_name + '_' + self.dd_type + '_'+ rule + '_'+ str(self.attackers_ratio) + '_' + str(self.local_epochs) + '.t7'
            torch.save(state,savepath)

            del local_models
            del local_weights
            del local_grads
            gc.collect()
            torch.cuda.empty_cache()
            # print("***********************************************************************************")
            
            # è¯¦ç»†æ··æ·†çŸ©é˜µåˆ†æ (å¯é€‰æ˜¾ç¤º)
            # print("\n=== å®Œæ•´æ··æ·†çŸ©é˜µåˆ†æ ===")
            # print("æ··æ·†çŸ©é˜µ (è¡Œ=çœŸå®æ ‡ç­¾, åˆ—=é¢„æµ‹æ ‡ç­¾):")
            # print(cm)
            # print("\nå„ç±»åˆ«æ ·æœ¬æ•°é‡åˆ†å¸ƒ:")
            total_samples = 0
            for i, class_name in enumerate(classes):
                class_total = cm[i].sum()
                total_samples += class_total
            #     print(f"{self.labels_dict[class_name]:25}: {class_total:4d} æ ·æœ¬")
            # print(f"{'æ€»æ ·æœ¬æ•°':25}: {total_samples:4d}")
            
            print('\n{0:10s} - {1:>8s} - {2:>8s} - {3:>8s}'.format('Class','Accuracy','Correct','Total'))
            print('-' * 60)
            correct_predictions = 0
            for i, r in enumerate(cm):
                class_accuracy = r[i]/np.sum(r)*100 if np.sum(r) > 0 else 0
                correct_predictions += r[i]
                print('{:25} - {:6.1f}% - {:6d} - {:6d}'.format(
                    self.labels_dict[classes[i]], 
                    class_accuracy,
                    r[i], 
                    np.sum(r)
                ))
                if i == source_class:
                    print(f"[è½®æ¬¡{epoch+1} ASR] æºç±»åˆ«{source_class}->ç›®æ ‡ç±»åˆ«{target_class}: {current_asr:.2f}%")
            
            # éªŒè¯å…¨å±€å‡†ç¡®ç‡è®¡ç®—
            manual_global_acc = correct_predictions / total_samples * 100
            # print(f"\næ‰‹åŠ¨è®¡ç®—çš„å…¨å±€å‡†ç¡®ç‡: {manual_global_acc:.2f}%")
            print(f"testå‡½æ•°è®¡ç®—çš„å…¨å±€å‡†ç¡®ç‡: {current_accuracy:.2f}%")
            # print("=== æ··æ·†çŸ©é˜µåˆ†æç»“æŸ ===\n")

            if epoch == self.global_rounds-1:
                print('Last 10 updates results')
                global_weights = average_weights(last10_updates, 
                np.ones([len(last10_updates)]))
                simulation_model.load_state_dict(global_weights) 
                current_accuracy, test_loss, current_f1 = self.test(simulation_model, self.device, self.test_loader, dataset_name=self.dataset_name)
                global_accuracies.append(np.round(current_accuracy, 2))
                global_f1_scores.append(np.round(current_f1, 2))
                test_losses.append(np.round(test_loss, 4))
                performed_attacks.append(attacks)
                print("***********************************************************************************")
                #print and show confusion matrix after each global round
                actuals, predictions = self.test_label_predictions(simulation_model, self.device, self.test_loader, dataset_name=self.dataset_name)
                classes = list(self.labels_dict.keys())
                from sklearn.metrics import confusion_matrix
                cm = confusion_matrix(actuals, predictions, labels=classes)
                
                # æœ€ç»ˆè½®æ¬¡çš„å®Œæ•´æ··æ·†çŸ©é˜µè¾“å‡º
                # print("\n=== æœ€ç»ˆè½®æ¬¡å®Œæ•´æ··æ·†çŸ©é˜µåˆ†æ ===")
                # print("æ··æ·†çŸ©é˜µ (è¡Œ=çœŸå®æ ‡ç­¾, åˆ—=é¢„æµ‹æ ‡ç­¾):")
                # print(cm)
                # print("\nå„ç±»åˆ«æ ·æœ¬æ•°é‡åˆ†å¸ƒ:")
                total_samples = 0
                for i, class_name in enumerate(classes):
                    class_total = cm[i].sum()
                    total_samples += class_total
                    # print(f"{self.labels_dict[class_name]:25}: {class_total:4d} æ ·æœ¬")
                # print(f"{'æ€»æ ·æœ¬æ•°':25}: {total_samples:4d}")
                
                print('\n{0:10s} - {1:>8s} - {2:>8s} - {3:>8s}'.format('Class','Accuracy','Correct','Total'))
                print('-' * 60)
                correct_predictions = 0
                asr = 0.0  # åˆå§‹åŒ–ASR
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç§»ä½æ”»å‡»ï¼ˆä½¿ç”¨MULTI_TARGET_ATTACKé…ç½®ï¼‰
                is_shift_attack = False
                attack_mappings = {}
                if attack_config and attack_config.get('type') == 'multi_target':
                    is_shift_attack = True
                    attack_mappings = attack_config.get('mappings', {})
                
                if is_shift_attack:
                    # ç§»ä½æ”»å‡»çš„æœ€ç»ˆASRè®¡ç®—
                    total_source_samples = 0
                    total_successful_attacks = 0
                    
                    for i, r in enumerate(cm):
                        class_accuracy = r[i]/np.sum(r)*100 if np.sum(r) > 0 else 0
                        correct_predictions += r[i]
                        print('{:25} - {:6.1f}% - {:6d} - {:6d}'.format(
                            self.labels_dict[classes[i]], 
                            class_accuracy,
                            r[i], 
                            np.sum(r)
                        ))
                        
                        # å¦‚æœå½“å‰ç±»æ˜¯æ”»å‡»æ˜ å°„ä¸­çš„æºç±»åˆ«
                        if i in attack_mappings:
                            tgt_class = attack_mappings[i]
                            source_samples = np.sum(r)
                            successful_attacks = r[tgt_class]
                            total_source_samples += source_samples
                            total_successful_attacks += successful_attacks
                            
                            # å¦‚æœæ˜¯ä¸»è¦æºç±»åˆ«ï¼Œè®°å½•å…¶å‡†ç¡®ç‡
                            if i == source_class:
                                source_class_accuracies.append(np.round(class_accuracy, 2))
                                
                    # è®¡ç®—å…¨å±€ASR
                    if total_source_samples > 0:
                        asr = np.round(total_successful_attacks/total_source_samples*100, 2)
                    print(f"\n[æœ€ç»ˆç§»ä½æ”»å‡»ASR] æ€»æºæ ·æœ¬: {total_source_samples}, æˆåŠŸæ”»å‡»: {total_successful_attacks}, ASR: {asr:.2f}%")
                    
                    # æ˜¾ç¤ºæ¯ä¸ªç±»åˆ«çš„è¯¦ç»†ASR
                    print("\nå„ç±»åˆ«ASRè¯¦æƒ…:")
                    for src_class, tgt_class in attack_mappings.items():
                        if src_class < len(cm) and np.sum(cm[src_class]) > 0:
                            class_asr = np.round(cm[src_class][tgt_class]/np.sum(cm[src_class])*100, 2)
                            print(f"[æœ€ç»ˆASR] æºç±»åˆ«{src_class}({self.labels_dict.get(src_class, 'æœªçŸ¥')})â†’ç›®æ ‡ç±»åˆ«{tgt_class}({self.labels_dict.get(tgt_class, 'æœªçŸ¥')}): {class_asr:.2f}%")
                else:
                    # ä¼ ç»Ÿå•ä¸€æº-ç›®æ ‡æ”»å‡»çš„ASRè®¡ç®—
                    for i, r in enumerate(cm):
                        class_accuracy = r[i]/np.sum(r)*100 if np.sum(r) > 0 else 0
                        correct_predictions += r[i]
                        print('{:25} - {:6.1f}% - {:6d} - {:6d}'.format(
                            self.labels_dict[classes[i]], 
                            class_accuracy,
                            r[i], 
                            np.sum(r)
                        ))
                        if i == source_class:
                            source_class_accuracies.append(np.round(class_accuracy, 2))
                            # ä¿®æ­£ASRè®¡ç®—ï¼šæºç±»åˆ«æ ·æœ¬ä¸­è¢«é¢„æµ‹ä¸ºç›®æ ‡ç±»åˆ«çš„æ¯”ä¾‹
                            if np.sum(r) > 0:
                                asr = np.round(r[target_class]/np.sum(r)*100, 2)
                            else:
                                asr = 0.0
                            print(f"[ASRè®¡ç®—] æºç±»åˆ«{source_class}æ€»æ ·æœ¬: {np.sum(r)}, è¢«é¢„æµ‹ä¸ºç›®æ ‡ç±»åˆ«{target_class}: {r[target_class]}, ASR: {asr:.2f}%")
                
                # éªŒè¯å…¨å±€å‡†ç¡®ç‡è®¡ç®—
                manual_global_acc = correct_predictions / total_samples * 100
                # print(f"\næ‰‹åŠ¨è®¡ç®—çš„å…¨å±€å‡†ç¡®ç‡: {manual_global_acc:.2f}%")
                print(f"testå‡½æ•°è®¡ç®—çš„å…¨å±€å‡†ç¡®ç‡: {current_accuracy:.2f}%")
                # print("=== æœ€ç»ˆæ··æ·†çŸ©é˜µåˆ†æç»“æŸ ===\n")

        # å®éªŒç»“æŸåå†™æœ€ç»ˆç»“æœ
        final_msg = (
            f"Experiment End | Rule: {rule} | Global Accuracies: {global_accuracies} | "
            f"Source Class Accuracies: {source_class_accuracies} | Test Losses: {test_losses}"
        )
        print(final_msg)
        logging.info(final_msg)

        state = {
                'state_dict': simulation_model.state_dict(),
                'test_losses': test_losses,
                'global_accuracies': global_accuracies,
                'global_f1_scores': global_f1_scores,
                'source_class_accuracies': source_class_accuracies,
                'asr':asr,
                'avg_cpu_runtime':np.mean(cpu_runtimes)
                }
        savepath = './results/'+ self.dataset_name + '_' + self.model_name + '_' + self.dd_type + '_'+ rule + '_'+ str(self.attackers_ratio) + '_' + str(self.local_epochs) + '.t7'
        torch.save(state,savepath)            
        print('Global accuracies: ', global_accuracies)
        print('Class {} accuracies: '.format(source_class), source_class_accuracies)
        print('Test loss:', test_losses)
        print('Attack succes rate:', asr)
        print('Average CPU aggregation runtime:', np.mean(cpu_runtimes))
        
        # å…³é—­PDFæ–‡ä»¶
        if rule == 'lfighter':
            lfd.finalize_pdf()
        elif rule == 'lfighter_ae':
            lfighter_ae.finalize_pdf()
        
        # è¿”å›æœ€ç»ˆç»“æœç»™è°ƒç”¨è€…
        final_accuracy = global_accuracies[-1] if global_accuracies else 0.0
        final_asr = asr if 'asr' in locals() else 0.0
        return final_accuracy, final_asr
