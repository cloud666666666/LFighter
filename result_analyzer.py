#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®éªŒç»“æœåˆ†æå™¨ - ç”¨äºè¯»å–å’Œåˆ†æ.t7æ ¼å¼çš„å®éªŒç»“æœæ–‡ä»¶
"""

import torch
import numpy as np
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import re
from pathlib import Path

class ResultAnalyzer:
    def __init__(self, results_dir="./results"):
        self.results_dir = Path(results_dir)
        self.results = {}
        self.df = None
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
    def load_all_results(self):
        """åŠ è½½æ‰€æœ‰.t7ç»“æœæ–‡ä»¶"""
        if not self.results_dir.exists():
            print(f"ç»“æœç›®å½• {self.results_dir} ä¸å­˜åœ¨ï¼")
            return
        
        t7_files = list(self.results_dir.glob("*.t7"))
        if not t7_files:
            print(f"åœ¨ {self.results_dir} ä¸­æœªæ‰¾åˆ°.t7æ–‡ä»¶ï¼")
            return
        
        print(f"æ‰¾åˆ° {len(t7_files)} ä¸ªç»“æœæ–‡ä»¶")
        
        for file_path in t7_files:
            try:
                # è§£ææ–‡ä»¶å
                filename = file_path.stem
                parts = filename.split('_')
                
                if len(parts) >= 5:
                    dataset = parts[0]
                    model = parts[1] 
                    
                    # å¤„ç†æ•°æ®åˆ†å¸ƒç±»å‹ (å¯èƒ½æ˜¯NON_IIDç­‰å¤åˆåç§°)
                    if len(parts) >= 6 and parts[2] == 'NON' and parts[3] == 'IID':
                        dd_type = 'NON_IID'
                        rule = '_'.join(parts[4:-2])
                    else:
                        dd_type = parts[2]
                        rule = '_'.join(parts[3:-2])  # å¤„ç†å¯èƒ½çš„å¤šéƒ¨åˆ†è§„åˆ™å
                    
                    attackers_ratio = parts[-2]
                    local_epochs = parts[-1]
                else:
                    print(f"è·³è¿‡æ–‡ä»¶åæ ¼å¼ä¸æ­£ç¡®çš„æ–‡ä»¶: {filename}")
                    continue
                
                # åŠ è½½ç»“æœï¼ˆå…¼å®¹PyTorch 2.6+ï¼‰
                result = torch.load(file_path, map_location='cpu', weights_only=False)
                
                # æå–å…³é”®ä¿¡æ¯
                exp_info = {
                    'file_path': str(file_path),
                    'dataset': dataset,
                    'model': model,
                    'dd_type': dd_type,
                    'rule': rule,
                    'attackers_ratio': float(attackers_ratio),
                    'local_epochs': int(local_epochs),
                    'final_accuracy': result.get('global_accuracies', [0])[-1] if result.get('global_accuracies') else 0,
                    'max_accuracy': max(result.get('global_accuracies', [0])) if result.get('global_accuracies') else 0,
                    'final_loss': result.get('test_losses', [float('inf')])[-1] if result.get('test_losses') else float('inf'),
                    'min_loss': min(result.get('test_losses', [float('inf')])) if result.get('test_losses') else float('inf'),
                    'asr': result.get('asr', 0),
                    'avg_cpu_runtime': result.get('avg_cpu_runtime', 0),
                    'global_accuracies': result.get('global_accuracies', []),
                    'test_losses': result.get('test_losses', []),
                    'source_class_accuracies': result.get('source_class_accuracies', [])
                }
                
                key = f"{dataset}_{model}_{dd_type}_{rule}_{attackers_ratio}_{local_epochs}"
                self.results[key] = exp_info
                
                print(f"âœ“ åŠ è½½: {filename}")
                
            except Exception as e:
                print(f"âœ— åŠ è½½å¤±è´¥: {filename} - {e}")
        
        print(f"\næˆåŠŸåŠ è½½ {len(self.results)} ä¸ªå®éªŒç»“æœ")
        self._create_dataframe()
    
    def _create_dataframe(self):
        """å°†ç»“æœè½¬æ¢ä¸ºDataFrameä»¥ä¾¿åˆ†æ"""
        if not self.results:
            return
        
        data = []
        for key, result in self.results.items():
            row = {
                'experiment': key,
                'dataset': result['dataset'],
                'model': result['model'],
                'dd_type': result['dd_type'],
                'rule': result['rule'],
                'attackers_ratio': result['attackers_ratio'],
                'local_epochs': result['local_epochs'],
                'final_accuracy': result['final_accuracy'],
                'max_accuracy': result['max_accuracy'],
                'final_loss': result['final_loss'],
                'min_loss': result['min_loss'],
                'asr': result['asr'],
                'cpu_runtime': result['avg_cpu_runtime']
            }
            data.append(row)
        
        self.df = pd.DataFrame(data)
        print(f"\næ•°æ®æ¡†åˆ›å»ºå®Œæˆï¼Œå…± {len(self.df)} æ¡è®°å½•")
    
    def show_summary(self):
        """æ˜¾ç¤ºå®éªŒç»“æœæ‘˜è¦"""
        if self.df is None:
            print("è¯·å…ˆåŠ è½½ç»“æœæ–‡ä»¶ï¼")
            return
        
        print("\n" + "="*60)
        print("ğŸ“Š å®éªŒç»“æœæ‘˜è¦")
        print("="*60)
        
        print(f"æ€»å®éªŒæ•°é‡: {len(self.df)}")
        print(f"æ•°æ®é›†: {self.df['dataset'].unique()}")
        print(f"æ¨¡å‹: {self.df['model'].unique()}")
        print(f"èšåˆè§„åˆ™: {self.df['rule'].unique()}")
        print(f"æ”»å‡»è€…æ¯”ä¾‹: {sorted(self.df['attackers_ratio'].unique())}")
        
        print("\nğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
        print(f"æœ€é«˜å‡†ç¡®ç‡: {self.df['max_accuracy'].max():.2f}%")
        print(f"å¹³å‡å‡†ç¡®ç‡: {self.df['final_accuracy'].mean():.2f}%")
        print(f"æœ€ä½æŸå¤±: {self.df['min_loss'].min():.4f}")
        print(f"å¹³å‡ASR: {self.df['asr'].mean():.2f}%")
        
        # æŒ‰è§„åˆ™åˆ†ç»„çš„æ€§èƒ½
        print("\nğŸ“‹ å„èšåˆè§„åˆ™æ€§èƒ½å¯¹æ¯”:")
        rule_stats = self.df.groupby('rule').agg({
            'final_accuracy': ['mean', 'std', 'max'],
            'asr': ['mean', 'std'],
            'cpu_runtime': ['mean', 'std']
        }).round(3)
        
        print(rule_stats)
    
    def compare_rules(self, metrics=['final_accuracy', 'asr', 'cpu_runtime']):
        """æ¯”è¾ƒä¸åŒèšåˆè§„åˆ™çš„æ€§èƒ½"""
        if self.df is None:
            print("è¯·å…ˆåŠ è½½ç»“æœæ–‡ä»¶ï¼")
            return
        
        rules = self.df['rule'].unique()
        n_metrics = len(metrics)
        
        fig, axes = plt.subplots(1, n_metrics, figsize=(5*n_metrics, 5))
        if n_metrics == 1:
            axes = [axes]
        
        for i, metric in enumerate(metrics):
            ax = axes[i]
            
            # ç®±çº¿å›¾
            sns.boxplot(data=self.df, x='rule', y=metric, ax=ax)
            ax.set_title(f'{metric} å¯¹æ¯”')
            ax.tick_params(axis='x', rotation=45)
            
            # æ·»åŠ å‡å€¼ç‚¹
            rule_means = self.df.groupby('rule')[metric].mean()
            for j, rule in enumerate(rules):
                ax.scatter(j, rule_means[rule], color='red', s=50, zorder=5)
        
        plt.tight_layout()
        plt.show()
    
    def plot_convergence(self, filter_dict=None):
        """ç»˜åˆ¶æ”¶æ•›æ›²çº¿"""
        if self.df is None:
            print("è¯·å…ˆåŠ è½½ç»“æœæ–‡ä»¶ï¼")
            return
        
        # ç­›é€‰å®éªŒ
        filtered_results = self.results
        if filter_dict:
            filtered_results = {k: v for k, v in self.results.items() 
                              if all(v.get(key) == value for key, value in filter_dict.items())}
        
        if not filtered_results:
            print("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å®éªŒç»“æœï¼")
            return
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # å‡†ç¡®ç‡æ›²çº¿
        for key, result in filtered_results.items():
            accuracies = result['global_accuracies']
            if accuracies:
                ax1.plot(accuracies, label=result['rule'], marker='o', markersize=4)
        
        ax1.set_xlabel('è®­ç»ƒè½®æ¬¡')
        ax1.set_ylabel('å…¨å±€å‡†ç¡®ç‡ (%)')
        ax1.set_title('è®­ç»ƒå‡†ç¡®ç‡æ”¶æ•›æ›²çº¿')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # æŸå¤±æ›²çº¿
        for key, result in filtered_results.items():
            losses = result['test_losses']
            if losses:
                ax2.plot(losses, label=result['rule'], marker='s', markersize=4)
        
        ax2.set_xlabel('è®­ç»ƒè½®æ¬¡')
        ax2.set_ylabel('æµ‹è¯•æŸå¤±')
        ax2.set_title('æµ‹è¯•æŸå¤±æ”¶æ•›æ›²çº¿')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def show_best_results(self, metric='final_accuracy', top_k=5):
        """æ˜¾ç¤ºæœ€ä½³ç»“æœ"""
        if self.df is None:
            print("è¯·å…ˆåŠ è½½ç»“æœæ–‡ä»¶ï¼")
            return
        
        ascending = metric in ['final_loss', 'min_loss', 'asr', 'cpu_runtime']
        best_results = self.df.nlargest(top_k, metric) if not ascending else self.df.nsmallest(top_k, metric)
        
        print(f"\nğŸ† {metric} æ’åå‰ {top_k} çš„å®éªŒ:")
        print("-" * 80)
        
        for idx, (_, row) in enumerate(best_results.iterrows(), 1):
            print(f"{idx}. {row['rule']} (æ”»å‡»è€…æ¯”ä¾‹: {row['attackers_ratio']})")
            print(f"   å‡†ç¡®ç‡: {row['final_accuracy']:.2f}% | ASR: {row['asr']:.2f}% | è¿è¡Œæ—¶é—´: {row['cpu_runtime']:.3f}s")
            print(f"   æ•°æ®é›†: {row['dataset']} | æ¨¡å‹: {row['model']}")
            print()
    
    def export_results(self, output_path="experiment_results.csv"):
        """å¯¼å‡ºç»“æœåˆ°CSVæ–‡ä»¶"""
        if self.df is None:
            print("è¯·å…ˆåŠ è½½ç»“æœæ–‡ä»¶ï¼")
            return
        
        self.df.to_csv(output_path, index=False)
        print(f"ç»“æœå·²å¯¼å‡ºåˆ°: {output_path}")
    
    def search_experiments(self, **kwargs):
        """æœç´¢ç‰¹å®šçš„å®éªŒç»“æœ"""
        if self.df is None:
            print("è¯·å…ˆåŠ è½½ç»“æœæ–‡ä»¶ï¼")
            return
        
        filtered_df = self.df.copy()
        
        for key, value in kwargs.items():
            if key in filtered_df.columns:
                if isinstance(value, (list, tuple)):
                    filtered_df = filtered_df[filtered_df[key].isin(value)]
                else:
                    filtered_df = filtered_df[filtered_df[key] == value]
        
        print(f"\nğŸ” æœç´¢ç»“æœ (å…± {len(filtered_df)} æ¡):")
        if len(filtered_df) > 0:
            print(filtered_df[['rule', 'attackers_ratio', 'final_accuracy', 'asr', 'cpu_runtime']].to_string(index=False))
        else:
            print("æœªæ‰¾åˆ°åŒ¹é…çš„å®éªŒç»“æœ")
        
        return filtered_df

def main():
    """ä¸»å‡½æ•° - äº¤äº’å¼ç»“æœåˆ†æ"""
    analyzer = ResultAnalyzer()
    
    print("ğŸ”¬ è”é‚¦å­¦ä¹ å®éªŒç»“æœåˆ†æå™¨")
    print("=" * 50)
    
    # åŠ è½½æ‰€æœ‰ç»“æœ
    analyzer.load_all_results()
    
    if not analyzer.results:
        print("æœªæ‰¾åˆ°ä»»ä½•ç»“æœæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥resultsç›®å½•ï¼")
        return
    
    # æ˜¾ç¤ºæ‘˜è¦
    analyzer.show_summary()
    
    # äº¤äº’å¼èœå•
    while True:
        print("\n" + "="*50)
        print("ğŸ“‹ é€‰æ‹©æ“ä½œ:")
        print("1. æ˜¾ç¤ºæœ€ä½³ç»“æœ")
        print("2. æ¯”è¾ƒèšåˆè§„åˆ™")
        print("3. ç»˜åˆ¶æ”¶æ•›æ›²çº¿")
        print("4. æœç´¢å®éªŒ")
        print("5. å¯¼å‡ºç»“æœ")
        print("6. é‡æ–°åŠ è½½")
        print("0. é€€å‡º")
        print("="*50)
        
        choice = input("è¯·è¾“å…¥é€‰æ‹© (0-6): ").strip()
        
        if choice == '0':
            print("ğŸ‘‹ å†è§ï¼")
            break
        elif choice == '1':
            metric = input("é€‰æ‹©æŒ‡æ ‡ (final_accuracy/asr/cpu_runtime): ").strip() or 'final_accuracy'
            analyzer.show_best_results(metric=metric)
        elif choice == '2':
            analyzer.compare_rules()
        elif choice == '3':
            # å¯ä»¥æ·»åŠ ç­›é€‰æ¡ä»¶
            print("ç»˜åˆ¶æ‰€æœ‰å®éªŒçš„æ”¶æ•›æ›²çº¿...")
            analyzer.plot_convergence()
        elif choice == '4':
            print("æœç´¢ç¤ºä¾‹: rule='lfighter_dbo', attackers_ratio=0.2")
            search_input = input("è¾“å…¥æœç´¢æ¡ä»¶ (æ ¼å¼: key=value, key=value): ").strip()
            if search_input:
                try:
                    search_dict = {}
                    for item in search_input.split(','):
                        key, value = item.split('=')
                        key = key.strip()
                        value = value.strip().strip("'\"")
                        # å°è¯•è½¬æ¢æ•°å€¼
                        try:
                            value = float(value)
                            if value.is_integer():
                                value = int(value)
                        except ValueError:
                            pass
                        search_dict[key] = value
                    analyzer.search_experiments(**search_dict)
                except Exception as e:
                    print(f"æœç´¢æ ¼å¼é”™è¯¯: {e}")
        elif choice == '5':
            filename = input("è¾“å…¥æ–‡ä»¶å (é»˜è®¤: experiment_results.csv): ").strip() or "experiment_results.csv"
            analyzer.export_results(filename)
        elif choice == '6':
            analyzer.load_all_results()
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")

if __name__ == "__main__":
    main() 